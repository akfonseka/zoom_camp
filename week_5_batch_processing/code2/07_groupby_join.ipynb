{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d711597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/21 13:42:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyarrow\n",
    "import pandas as pd\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd799969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('data/raw/green/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf842c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green.registerTempTable('green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4cab4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'lpep_pickup_datetime',\n",
       " 'lpep_dropoff_datetime',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'ehail_fee',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'payment_type',\n",
       " 'trip_type',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b004eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Revenue grouping \n",
    "    date_trunc('hour', lpep_pickup_datetime) AS hour,  \n",
    "    PULocationID AS zone,\n",
    "    \n",
    "    -- Revenue calculation \n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) as number_records\n",
    "\n",
    "FROM\n",
    "    green\n",
    "where lpep_pickup_datetime >= '2020-01-01 00:00'\n",
    "GROUP BY\n",
    "    1, 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c175484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green_revenue.write.parquet('data/report/revenue/green', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf428fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad169314",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read.parquet('data/raw/yellow/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "320b0a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arith/spark/spark-3.4.0-bin-hadoop3/python/pyspark/sql/dataframe.py:330: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_yellow.registerTempTable('yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f99b07b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Revenue grouping \n",
    "    date_trunc('hour', tpep_pickup_datetime) AS hour,  \n",
    "    PULocationID AS zone,\n",
    "    \n",
    "    -- Revenue calculation \n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) as number_records\n",
    "\n",
    "FROM\n",
    "    yellow\n",
    "where tpep_pickup_datetime >= '2020-01-01 00:00'\n",
    "GROUP BY\n",
    "    1, 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ef125e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_yellow_revenue \\\n",
    "    .repartition(20) \\\n",
    "    .write.parquet('data/report/revenue/yellow', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2226dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_revenue = spark.read.parquet('data/report/revenue/yellow/')\n",
    "df_green_revenue = spark.read.parquet('data/report/revenue/green/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eea6e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue_tmp = df_green_revenue \\\n",
    "    .withColumnRenamed('amount', 'green_amount') \\\n",
    "    .withColumnRenamed('number_records', 'green_number_records') \n",
    "\n",
    "df_yellow_revenue_tmp = df_yellow_revenue \\\n",
    "    .withColumnRenamed('amount', 'yellow_amount') \\\n",
    "    .withColumnRenamed('number_records', 'yellow_number_records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0435007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_green_revenue_tmp.join(df_yellow_revenue_tmp, on=['hour', 'zone'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd149bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join \\\n",
    "    .write.parquet('data/report/revenue/total', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a5243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = spark.read.parquet('data/report/revenue/total/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb76968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "|               hour|zone|      green_amount|green_number_records|     yellow_amount|yellow_number_records|\n",
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "|2020-01-01 00:00:00|   4|              null|                null|1004.2999999999995|                   57|\n",
      "|2020-01-01 00:00:00|   7| 769.7299999999997|                  45| 455.1700000000002|                   38|\n",
      "|2020-01-01 00:00:00|  22|              15.8|                   1|              null|                 null|\n",
      "|2020-01-01 00:00:00|  25|             531.0|                  26| 324.3500000000001|                   16|\n",
      "|2020-01-01 00:00:00|  33|317.27000000000004|                  11|            255.56|                    8|\n",
      "|2020-01-01 00:00:00|  34|              null|                null|              19.3|                    1|\n",
      "|2020-01-01 00:00:00|  41| 1363.959999999999|                  84|1256.5299999999988|                   80|\n",
      "|2020-01-01 00:00:00|  43|            107.52|                   6| 6539.510000000026|                  390|\n",
      "|2020-01-01 00:00:00|  49|            266.76|                  14|            185.65|                   10|\n",
      "|2020-01-01 00:00:00|  52|             83.33|                   4|              49.8|                    2|\n",
      "|2020-01-01 00:00:00|  56|             99.69|                   3|              18.1|                    2|\n",
      "|2020-01-01 00:00:00|  59|50.900000000000006|                   3|              null|                 null|\n",
      "|2020-01-01 00:00:00|  60|            160.04|                   6|57.620000000000005|                    2|\n",
      "|2020-01-01 00:00:00|  62|             15.95|                   1|             61.43|                    1|\n",
      "|2020-01-01 00:00:00|  63|              51.9|                   2|              70.8|                    1|\n",
      "|2020-01-01 00:00:00|  74| 317.0900000000001|                  24|            586.21|                   47|\n",
      "|2020-01-01 00:00:00|  94| 64.24000000000001|                   3|              13.3|                    1|\n",
      "|2020-01-01 00:00:00|  97| 786.1799999999998|                  25|403.02000000000004|                   20|\n",
      "|2020-01-01 00:00:00| 119| 67.77000000000001|                   4|              47.3|                    2|\n",
      "|2020-01-01 00:00:00| 130|            133.35|                   7|              null|                 null|\n",
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8fed6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_zones = spark.read.parquet('zones/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7c195bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "05e436b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hour: timestamp, zone: bigint, green_amount: double, green_number_records: bigint, yellow_amount: double, yellow_number_records: bigint]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b9838ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_join.join(df_zones, df_join.zone==df_zones.LocationID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e39eb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result \\\n",
    "    .drop('LocationID', 'zone') \\\n",
    "    .write.parquet('tmp/revenue-zones', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a47dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
